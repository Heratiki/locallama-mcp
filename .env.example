# Local LLM Endpoints
LM_STUDIO_ENDPOINT=http://localhost:1234/v1
OLLAMA_ENDPOINT=http://localhost:11434/api

# Configuration
DEFAULT_LOCAL_MODEL=llama3
TOKEN_THRESHOLD=1000
COST_THRESHOLD=0.02
QUALITY_THRESHOLD=0.7

# Logging
LOG_LEVEL=info